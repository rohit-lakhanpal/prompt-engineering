{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Before we can start having fun, let's setup the key libraries and functions we'll need. These will allow us to:\n",
    "- Call OpenAI's API\n",
    "- Call Bing's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv\n",
    "%pip install pprintpp\n",
    "%pip install openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Variables\n",
    "\n",
    "Create an `.env` file in the root directory of this project. It should contain the following variables:\n",
    "\n",
    "```env\n",
    "BING_SEARCH_V7_SUBSCRIPTION_KEY=\"<your key here>\"\n",
    "BING_SEARCH_V7_ENDPOINT=\"https://api.bing.microsoft.com/\"\n",
    "OPENAI_KEY=\"<your openai key>\"\n",
    "OPENAI_AZURE_KEY=\"<your azure openai key>\"\n",
    "OPENAI_AZURE_BASE_URL=\"<your azure openai endpoint>\"\n",
    "OPENAI_AZURE_API_VERSION=\"2023-05-15\"\n",
    "OPENAI_AZURE_CHAT_COMPLETION_DEPLOYMENT_NAME=\"<your azure openai deployment name for gpt 3.5 or gpt 4>\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "import os\n",
    "from pprint import pprint\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create helper functions\n",
    "These are helper functions that will allow us to call the APIs and get the results we need.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Search for content using Bing Search using `bing_search`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns search results via Bing Search API\n",
    "def bing_search(query):\n",
    "    # Add your Bing Search V7 subscription key and endpoint to your environment variables.\n",
    "    subscription_key = os.environ[\"BING_SEARCH_V7_SUBSCRIPTION_KEY\"]    \n",
    "    endpoint = os.environ[\"BING_SEARCH_V7_ENDPOINT\"] \n",
    "\n",
    "    # Ensure that the subscription key & endpoint have been set, else throw an error.\n",
    "    if not subscription_key or not endpoint:\n",
    "        raise Exception(\"Set your environment variables for your subscription key and endpoint.\")\n",
    "\n",
    "    # Add a trailing slash to the endpoint if needed\n",
    "    if endpoint[-1] != \"/\":\n",
    "        endpoint = endpoint + \"/\"\n",
    "    endpoint = endpoint + \"v7.0/search\"\n",
    "\n",
    "\n",
    "    # Construct a request\n",
    "    mkt = \"en-US\"\n",
    "    params = { \"q\": query, \"mkt\": mkt }\n",
    "    headers = { \"Ocp-Apim-Subscription-Key\": subscription_key }\n",
    "\n",
    "    # Call the API\n",
    "    try:\n",
    "        response = requests.get(endpoint, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        search_results = response.json()\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    \n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   {   'dateLastCrawled': '2023-06-26T02:04:00.0000000Z',\n",
      "        'deepLinks': [...],\n",
      "        'displayUrl': 'https://www.microsoft.com/en-us',\n",
      "        'id': 'https://api.bing.microsoft.com/api/v7/#WebPages.0',\n",
      "        'isFamilyFriendly': True,\n",
      "        'isNavigational': True,\n",
      "        'language': 'en',\n",
      "        'name': 'Microsoft – Cloud, Computers, Apps & Gaming',\n",
      "        'snippet': 'Explore Microsoft products and services for your home or business. Shop '\n",
      "                   'Surface, Microsoft 365, Xbox, Windows, Azure, and more. Find downloads and get '\n",
      "                   'support.',\n",
      "        'url': 'https://www.microsoft.com/en-us/'},\n",
      "    {   'dateLastCrawled': '2023-06-25T15:14:00.0000000Z',\n",
      "        'displayUrl': 'https://support.microsoft.com',\n",
      "        'id': 'https://api.bing.microsoft.com/api/v7/#WebPages.1',\n",
      "        'isFamilyFriendly': True,\n",
      "        'isNavigational': False,\n",
      "        'language': 'en',\n",
      "        'name': 'Microsoft Support',\n",
      "        'searchTags': [...],\n",
      "        'snippet': 'Microsoft support is here to help you with Microsoft products. Find how-to '\n",
      "                   'articles, videos, and training for Microsoft 365, Windows, Surface, and more.',\n",
      "        'url': 'https://support.microsoft.com/en-us'}]\n"
     ]
    }
   ],
   "source": [
    "# Perform a test search for the word \"Microsoft\"\n",
    "result = bing_search(\"Microsoft\")\n",
    "# Print the first 2 results within the JSON response.\n",
    "pprint(result[\"webPages\"][\"value\"][0:2], indent=4, width=100, depth=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Pretty Prining functions:\n",
    "\n",
    "    - `bold` - Print text in bold\n",
    "    - `wrap` - Wraps text with a default width of 100 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTesting the bold functionality.\u001b[0m\n",
      "\u001b[3mTesting the italic functionality.\u001b[0m\n",
      "The quick\n",
      "brown fox\n",
      "jumped\n",
      "over the\n",
      "lazy dog.\n",
      "\u001b[1m\n",
      "\n",
      "┌───────┐\u001b[0m\n",
      "\u001b[1m│Heading│\u001b[0m\n",
      "\u001b[1m└───────┘\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "def bold(text):\n",
    "    print(f'\\033[1m{text}\\033[0m')\n",
    "\n",
    "# Testing the bold function\n",
    "bold(\"Testing the bold functionality.\")\n",
    "\n",
    "def italic(text):\n",
    "    print(f'\\033[3m{text}\\033[0m')\n",
    "\n",
    "# Testing the italic function\n",
    "italic(\"Testing the italic functionality.\")\n",
    "\n",
    "def wrap(text, line_length=100):\n",
    "    for line in text.split('\\n'):\n",
    "        wrapper = textwrap.TextWrapper(width=line_length)\n",
    "        word_list = wrapper.wrap(text=line)\n",
    "\n",
    "        # Print each line\n",
    "        for l in word_list:\n",
    "            print(l)\n",
    "\n",
    "# Testing the wrap function\n",
    "wrap(\"The quick brown fox jumped over the lazy dog.\", 10)\n",
    "\n",
    "def box(text):    \n",
    "    bold(f'\\n\\n┌{\"─\" * len(text)}┐')\n",
    "    bold(f'│{text}│')\n",
    "    bold(f'└{\"─\" * len(text)}┘')\n",
    "\n",
    "# Testing the box function\n",
    "box(\"Heading\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Message helper functions: OpenAI's Chat Completions expects messages in the following format:\n",
    "    ```python\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who's there?\"}\n",
    "    ]\n",
    "    ```\n",
    "    To assist with this, we have the following functions:\n",
    "    \n",
    "    - `validate_message` - Validates that a message is in the expected format.\n",
    "    - `print_messages` - Prints messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages are valid!\n",
      "Messages are invalid because:\n",
      "Each message should be a dictionary\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "You are a helpful assistant.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Knock knock.\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Who's there?\n"
     ]
    }
   ],
   "source": [
    "def validate_messages(messages):\n",
    "    # Define the acceptable roles\n",
    "    valid_roles = [\"system\", \"user\", \"assistant\"]\n",
    "\n",
    "    # Check if messages is a list\n",
    "    if not isinstance(messages, list):\n",
    "        raise TypeError(\"Input should be a list\")\n",
    "\n",
    "    # Iterate over the list of messages\n",
    "    for message in messages:\n",
    "        # Check if message is a dictionary\n",
    "        if not isinstance(message, dict):\n",
    "            raise TypeError(\"Each message should be a dictionary\")\n",
    "\n",
    "        # Check if the necessary keys exist in the dictionary\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            raise ValueError(\"Each message should have 'role' and 'content' keys\")\n",
    "\n",
    "        # Check if role is valid\n",
    "        if message[\"role\"] not in valid_roles:\n",
    "            raise ValueError(f\"Role should be one of {valid_roles}\")\n",
    "\n",
    "    # If all messages pass the checks, return True\n",
    "    return True\n",
    "\n",
    "# Test valid messages\n",
    "if validate_messages([\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Who's there?\"}\n",
    "]):\n",
    "    print(\"Messages are valid!\")\n",
    "\n",
    "# Test invalid messages\n",
    "try:\n",
    "    validate_messages([\n",
    "        \"You are a helpful assistant.\",\n",
    "    ])\n",
    "except Exception as ex:    \n",
    "    print(\"Messages are invalid because:\")\n",
    "    print(ex)\n",
    "\n",
    "def print_messages(messages):\n",
    "    # Validate the messages first\n",
    "    if validate_messages(messages):\n",
    "        # Iterate over the messages and print each one in the desired format\n",
    "        for message in messages:                        \n",
    "            bold(f'\\n[{message[\"role\"]}]:')\n",
    "            wrap(message[\"content\"])\n",
    "\n",
    "# Test the print_messages function\n",
    "print_messages([\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Who's there?\"}\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Helper message to call the ChatCompletions endpoint (direct or via azure) using `perform_chat_completion`. \n",
    "    ***Note:*** Can call azure OR openai directly based on the type parameter. Defaults to openai.\n",
    "\n",
    "    This function has the following parameters:\n",
    "\n",
    "    | Parameter | Description | Is Required | Default Value |\n",
    "    | --- | --- | --- | --- |\n",
    "    | `messages` | The messages to send to the API. | Yes | N/A |\n",
    "    | `type` | The type of API to call. Can be `openai` or `azure`. | No | `openai` |\n",
    "    | `temperature` | What temperature to use for the API call. A value between 0 and 2 | No | `0` |\n",
    "    | `top_p` | What top_p to use for the API call. A value between 0 and 1 | No | `1` |\n",
    "    | `max_tokens` | What max_tokens to use for the API call. A value between 1 and 4096 | No | `2048` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# This function calls the OpenAI (or Azure OpenAI)'s completion endpoint\n",
    "def perform_chat_completion(messages, type=\"openai\", temperature=0, top_p=0.5, max_tokens=2048):\n",
    "    # perform checks else raise exception\n",
    "    if type != 'openai' and type != 'azure':\n",
    "        raise Exception(\"type must be either openai or azure\")\n",
    "    \n",
    "    validate_messages(messages)\n",
    "    \n",
    "    if temperature < 0 or temperature > 2:\n",
    "        raise Exception(\"temperature must be between 0 and 2\")\n",
    "    \n",
    "    if top_p < 0 or top_p > 1:\n",
    "        raise Exception(\"top_p must be between 0 and 1\")\n",
    "\n",
    "    if max_tokens < 1 or max_tokens > 4096:\n",
    "        raise Exception(\"max_tokens must be between 1 and 2048\")\n",
    "\n",
    "\n",
    "    # check if type is openai or azure\n",
    "    if type == \"openai\":        \n",
    "        if not os.environ[\"OPENAI_KEY\"]:\n",
    "            raise Exception(\"Set your OPENAI_KEY environment variable.\")\n",
    "        \n",
    "        import openai        \n",
    "        openai.api_type = \"openai\"\n",
    "        openai.api_version = None\n",
    "        openai.api_base = \"https://api.openai.com/v1/\"\n",
    "        openai.api_key = os.environ[\"OPENAI_KEY\"]\n",
    "            \n",
    "\n",
    "        try:\n",
    "            results = openai.ChatCompletion.create(\n",
    "                model='gpt-3.5-turbo',\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                top_p=top_p,\n",
    "                max_tokens=max_tokens\n",
    "            )\n",
    "        except Exception as ex:\n",
    "            raise ex\n",
    "    else:\n",
    "        if not os.environ[\"OPENAI_AZURE_KEY\"]:\n",
    "            raise Exception(\"Set your OPENAI_AZURE_KEY environment variable.\")\n",
    "        if not os.environ[\"OPENAI_AZURE_BASE_URL\"]:\n",
    "            raise Exception(\"Set your OPENAI_AZURE_BASE_URL environment variable.\")\n",
    "        if not os.environ[\"OPENAI_AZURE_API_VERSION\"]:\n",
    "            raise Exception(\"Set your OPENAI_AZURE_API_VERSION environment variable.\")\n",
    "        if not os.environ[\"OPENAI_AZURE_CHAT_COMPLETION_DEPLOYMENT_NAME\"]:\n",
    "            raise Exception(\"Set your OPENAI_AZURE_CHAT_COMPLETION_DEPLOYMENT_NAME environment variable.\")\n",
    "                \n",
    "        import openai\n",
    "        openai.api_type = 'azure'\n",
    "        openai.api_version = os.environ[\"OPENAI_AZURE_API_VERSION\"]\n",
    "        openai.api_base = os.environ[\"OPENAI_AZURE_BASE_URL\"]\n",
    "        openai.api_key = os.environ[\"OPENAI_AZURE_KEY\"]\n",
    "        \n",
    "        try:\n",
    "            results = openai.ChatCompletion.create(\n",
    "                deployment_id=os.environ[\"OPENAI_AZURE_CHAT_COMPLETION_DEPLOYMENT_NAME\"],\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                top_p=top_p,\n",
    "                max_tokens=max_tokens\n",
    "            )\n",
    "        except Exception as ex:\n",
    "            raise ex\n",
    "        \n",
    "    return results        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌──────────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Call Chat Completions endoint using OpenAI│\u001b[0m\n",
      "\u001b[1m└──────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "You are a helpful assistant.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Hi there.\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Note: You can skip this step if you are using Azure OpenAI Service\n",
    "box(\"Call Chat Completions endoint using OpenAI\")\n",
    "completion_message_request = [\n",
    "   {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "   {\"role\": \"user\", \"content\": \"Hi there.\"}\n",
    "]\n",
    "print_messages(completion_message_request)\n",
    "chat_completion = perform_chat_completion(completion_message_request, \"openai\")\n",
    "print_messages([chat_completion[\"choices\"][0][\"message\"]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌──────────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Call Chat Completions endoint using  Azure│\u001b[0m\n",
      "\u001b[1m└──────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "You are a helpful assistant.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Hi there.\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Note: You can skip this step if you are using OpenAI's API\n",
    "box(\"Call Chat Completions endoint using  Azure\")\n",
    "completion_message_request = [\n",
    "   {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "   {\"role\": \"user\", \"content\": \"Hi there.\"}\n",
    "]\n",
    "print_messages(completion_message_request)\n",
    "chat_completion = perform_chat_completion(completion_message_request, \"azure\")\n",
    "print_messages([chat_completion[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Engineering "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Simple conversational scenarios\n",
    "\n",
    "The following code snippet shows the most basic way to use the ChatGPT and GPT-4 models with the Chat Completion API. \n",
    "\n",
    "In this example we ask the model to complete the following conversation:\n",
    "```log\n",
    "system: You are a helpful assistant.\n",
    "user: Who were the founders of Microsoft?\n",
    "assistant:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌──────────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Example 1: Simple conversational scenarios│\u001b[0m\n",
      "\u001b[1m└──────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "You are a helpful assistant.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Who were the founders of Microsoft?\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "The founders of Microsoft are Bill Gates and Paul Allen.\n"
     ]
    }
   ],
   "source": [
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "prompt_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "box(\"Example 1: Simple conversational scenarios\")\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the code above, the chat completion API expects messages to be in the following format:   \n",
    "```json\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Orange.\"},\n",
    "]\n",
    "```\n",
    "\n",
    "Depending on the role you should use the following values:\n",
    "| Role | Purpose | Explaination | Example |\n",
    "| --- | --- | --- | --- |\n",
    "| `system` | Provide some context and/or instructions to the model. | The system message is included at the beginning of the prompt and is used to prime the model and you can include a variety of information in the system message including: <br> - A brief description of the assistant <br> - The personality of the assistant <br> - Instructions for the assistant <br> - Data or information needed for the model | `{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}` |\n",
    "| `user` | A question/message for the model to actually respond to. | After the system message, you can include a series of messages between the user and the assistant. You denote who the message is from by setting the role to user or assistant. | `{\"role\": \"user\", \"content\": \"Knock knock.\"}` |\n",
    "\n",
    "\n",
    "\n",
    "**⚠️ You might be wondering how this is different from the previous models.**\n",
    "\n",
    "Unlike previous GPT-3 models, the ChatGPT model is specifically designed to be a conversational interface. The conversational nature of the model makes it easier to interact with and to \u000btake advantage of the full power of its capabilities.\n",
    "\n",
    "Previous models were text-in and text-out (i.e., they accepted a prompt string and returned a completion to append to the prompt).\n",
    "\n",
    "The ChatGPT model is conversation-in and message-out. (i.e., it expects a prompt string that is formatted in a specific chat-like transcript format and returns a completion that represents a model-written message in the chat)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Non conversational scenarios\n",
    "\n",
    "While the Chat Completion API is optimized to work with multi-turn conversations, it also can be used for non chat scenarios. \n",
    "\n",
    "This example is set as follows:\n",
    "| Role | Explanation |\n",
    "| --- | --- | \n",
    "| `system` | You are an assistant designed to summarise this non-fiction books. Users will paste in a name of a book and you will respond with a short summary. Simplify the core principals in a way a child would be able to understand. | \n",
    "| `user` | Thinking, Fast and Slow by Daniel Kahneman |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌───────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Example 2: Non conversational scenarios│\u001b[0m\n",
      "\u001b[1m└───────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "You are an assistant designed to summarise this non-fiction books. Users will paste in a name of a\n",
      "book and you will respond with a short summary. Simplify the core principals in a way a child would\n",
      "be able to understand.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Thinking, Fast and Slow by Daniel Kahneman\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "\"Thinking, Fast and Slow\" is a book that talks about how our brain works in two different ways. One\n",
      "way is fast and automatic, like when we catch a ball without thinking. The other way is slow and\n",
      "deliberate, like when we solve a math problem. The book explains how these two ways of thinking can\n",
      "sometimes make us make mistakes, and how we can learn to make better decisions by being aware of\n",
      "them.\n"
     ]
    }
   ],
   "source": [
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "prompt_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an assistant designed to summarise this non-fiction books. Users will paste in a name of a book and you will respond with a short summary. Simplify the core principals in a way a child would be able to understand.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Thinking, Fast and Slow by Daniel Kahneman\"}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "box(\"Example 2: Non conversational scenarios\")\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Role Prompting\n",
    "\n",
    "Here lets explore the `Be specific` and `Be descriptive` best practices listed at https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/prompt-engineering#best-practices.\n",
    "\n",
    "- `Be Specific`: Leave as little to interpretation as possible. Restrict the operational space.\n",
    "- `Be Descriptive`: Use analogies.\n",
    "\n",
    "In this example we will show how being specific and descriptive can help us get better results. \n",
    "\n",
    "**Scenario 3.1: Basic prompt**\n",
    "\n",
    "| Role | Explanation |\n",
    "| --- | --- |\n",
    "| `user` | What is 1000*1000/20*50? |\n",
    "\n",
    "**Scenario 3.2: Better prompt using Role Prompting**\n",
    "\n",
    "| Role | Explanation |\n",
    "| --- | --- |\n",
    "| `system` | Assume you are a math teacher and you are going to teach Order Of Operations Activities (BODMAS, BIMDAS, PEMDAS, GEMS & More) to your students. |\n",
    "| `user` | What is 1000*1000/20*50? |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌──────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 3.1: Basic prompt│\u001b[0m\n",
      "\u001b[1m└──────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "What is 1000*1000/20*50?\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "1000*1000/20*50 = 50,000\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 3.1: Basic prompt\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "prompt_messages = [    \n",
    "    {\"role\": \"user\", \"content\": \"What is 1000*1000/20*50?\"}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌────────────────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 3.2: Better prompt using Role Prompting│\u001b[0m\n",
      "\u001b[1m└────────────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Assume you are a math teacher and you are going to teach PEMDAS (Parentheses, Exponents,\n",
      "Multiplication and Division from left to right, and Addition and Subtraction from left to right) to\n",
      "your students. What is 1000*1000/20*50?\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "To solve this problem using PEMDAS, we need to follow the order of operations:\n",
      "1. Parentheses (none)\n",
      "2. Exponents (none)\n",
      "3. Multiplication and Division from left to right:\n",
      "1000 * 1000 = 1,000,000\n",
      "1,000,000 / 20 = 50,000\n",
      "50,000 * 50 = 2,500,000\n",
      "4. Addition and Subtraction from left to right (none)\n",
      "Therefore, 1000*1000/20*50 = 2,500,000.\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 3.2: Better prompt using Role Prompting\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "prompt_messages = [    \n",
    "    {\"role\": \"user\", \"content\": \"Assume you are a math teacher and you are going to teach PEMDAS (Parentheses, Exponents, Multiplication and Division from left to right, and Addition and Subtraction from left to right) to your students. What is 1000*1000/20*50?\"}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Providing instructions to get expected results\n",
    "\n",
    "To ensure the model provides the expected results, you can provide instructions to the model within the system message.\n",
    "\n",
    "In this example, show the difference beteen providing instructions and not providing instructions. We will use the same prompt for both examples, but the system message will be different.\n",
    "\n",
    "**Scenario 4.1: No instructions**\n",
    "\n",
    "| Role | Explanation |\n",
    "| --- | --- |\n",
    "| `system` | You are an assistant designed to summarise this non-fiction books. Users will paste in a name of a book and you will respond with a short summary. Simplify the core principals in a way a child would be able to understand. |\n",
    "| `user` | How to build your Technology Strategy by Rohit Lakhanpal |\n",
    "\n",
    "**Scenario 4.2: With instructions**\n",
    "\n",
    "| Role | Explanation |\n",
    "| --- | --- |\n",
    "| `system` | You are an assistant designed to summarise this non-fiction books. Users will paste in a name of a book and you will respond with a short summary. Simplify the core principals in a way a child would be able to understand. <br> <br> **Instructions:** <br> - If you don't know about the book, say \"I don't know\". <br> - Don't make up information. |\n",
    "| `user` | How to build your Technology Strategy by Rohit Lakhanpal |\n",
    "\n",
    "\n",
    "**Note**: No book called \"How to build your Technology Strategy\" by \"Rohit Lakhanpal\" exists. The model will make up information if you don't provide instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌─────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 4.1: No instructions│\u001b[0m\n",
      "\u001b[1m└─────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "You are an assistant designed to summarise this non-fiction books. Users will paste in a name of a\n",
      "book and you will respond with a short summary. Simplify the core principals in a way a child would\n",
      "be able to understand.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "How to build your Technology Strategy by Rohit Lakhanpal\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "This book is about making a plan for using technology in a smart way. It helps you think about what\n",
      "you want to achieve with technology and how to make it happen. It's like making a map to get to your\n",
      "destination, but for technology!\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 4.1: No instructions\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "system_message = \"You are an assistant designed to summarise this non-fiction books. Users will paste in a name of a book and you will respond with a short summary. Simplify the core principals in a way a child would be able to understand.\"\n",
    "book = \"How to build your Technology Strategy by Rohit Lakhanpal\"\n",
    "prompt_messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": book}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌───────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 4.2: With instructions│\u001b[0m\n",
      "\u001b[1m└───────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "You are an assistant designed to summarise this non-fiction books. Users will paste in a name of a\n",
      "book and you will respond with a short summary. Simplify the core principals in a way a child would\n",
      "be able to understand.\n",
      "#Instructions:\n",
      "- If you don't know about the book, say \"I don't know\".\n",
      "- Don't make up information.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "How to be a Tech Stragist by Rohit Lakhanpal\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 4.2: With instructions\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "system_message = \"\"\"You are an assistant designed to summarise this non-fiction books. Users will paste in a name of a book and you will respond with a short summary. Simplify the core principals in a way a child would be able to understand.\n",
    "\n",
    "#Instructions:\n",
    "- If you don't know about the book, say \"I don't know\". \n",
    "- Don't make up information.\n",
    "\"\"\"\n",
    "prompt_messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": \"How to be a Tech Stragist by Rohit Lakhanpal\"}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in example above, when you don't provide instructions, the model will make up information. This is known as `hallucination`. To combat this, we used the system message to provide instructions to the model. This is part of the best practice known as `Giving the model an out`.\n",
    "\n",
    "**Give the model an out**: It can sometimes be helpful to give the model an alternative path if it is unable to complete the assigned task. For example, when asking a question over a piece of text you might include something like `respond with 'not found' if the answer is not present`. This can help the model avoid generating false responses.\n",
    "\n",
    "Learn more at https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/prompt-engineering#best-practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_messages = [\n",
    "#     {\"role\": \"system\", \"content\": \"\"},\n",
    "#     {\"role\": \"user\", \"content\": \"\"}\n",
    "# ]\n",
    "# completion_response = perform_chat_completion(prompt_messages)\n",
    "# print_messages(prompt_messages)\n",
    "# print_messages([completion_response[\"choices\"][0][\"message\"]])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: Zero Shot, One Shot, Few Shot\n",
    "\n",
    "In this example we will show how to use the `Zero Shot`, `One Shot` and `Few Shot` capabilities of the Chat Completion API. \n",
    "\n",
    "**Scenario 5.1: Zero Shot**\n",
    "\n",
    "Only the command and the unsolved input is provided to the model.\n",
    "\n",
    "| Role | Explanation |\n",
    "| --- | --- |\n",
    "| `system` | Suggest three names for an animal that is a superhero. |\n",
    "| `user` | Dog |\n",
    "\n",
    "\n",
    "**Scenario 5.2: One Shot**\n",
    "\n",
    "One example is provided to the model before an unsolved problem is asked.\n",
    "\n",
    "| Role | Explanation |\n",
    "| --- | --- |\n",
    "| `system` | Suggest three names for an animal that is a superhero. |\n",
    "| `user` | Cat |\n",
    "| `assistant` | Cat Damon, Pawsley Snipes and Audrey Hepurrn |\n",
    "| `user` | Dog |\n",
    "\n",
    "\n",
    "**Scenario 5.3: Few Shot**\n",
    "\n",
    "Few solved examples are provided to the model before an unsolved problem is asked.\n",
    "\n",
    "| Role | Explanation |\n",
    "| --- | --- |\n",
    "| `system` | Suggest three names for an animal that is a superhero. |\n",
    "| `user` | Cat |\n",
    "| `assistant` | Cat Damon, Pawsley Snipes and Audrey Hepurrn |\n",
    "| `user` | Horse |\n",
    "| `assistant` | Neigh-talie Portman, Gallop Gadot and David Hasselhoof |\n",
    "| `user` | Dog |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌────────────────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 5.1: Generate Dog named using Zero Shot│\u001b[0m\n",
      "\u001b[1m└────────────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "Suggest three names for an animal that is a superhero.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Dog\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "1. Superpup\n",
      "2. Mighty Mutt\n",
      "3. Captain Canine\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 5.1: Generate Dog named using Zero Shot\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "\n",
    "prompt_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Suggest three names for an animal that is a superhero.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Dog\"}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌───────────────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 5.2: Generate Dog named using One Shot│\u001b[0m\n",
      "\u001b[1m└───────────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "Suggest three names for an animal that is a superhero.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Cat\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Cat Damon, Pawsley Snipes and Audrey Hepurrn\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Dog\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Bark Kent, Captain Canine and Wonder Woof\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 5.2: Generate Dog named using One Shot\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "\n",
    "prompt_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Suggest three names for an animal that is a superhero.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Cat\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Cat Damon, Pawsley Snipes and Audrey Hepurrn\"},\n",
    "    {\"role\": \"user\", \"content\": \"Dog\"}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌───────────────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 5.3: Generate Dog named using Few Shot│\u001b[0m\n",
      "\u001b[1m└───────────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "Suggest three names for an animal that is a superhero.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Cat\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Cat Damon, Pawsley Snipes and Audrey Hepurrn\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Horse\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Neigh-talie Portman, Gallop Gadot and David Hasselhoof\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Dog\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Bark Kent, Wonder Pug and Captain Canine\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 5.3: Generate Dog named using Few Shot\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "\n",
    "prompt_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Suggest three names for an animal that is a superhero.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Cat\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Cat Damon, Pawsley Snipes and Audrey Hepurrn\"},    \n",
    "    {\"role\": \"user\", \"content\": \"Horse\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Neigh-talie Portman, Gallop Gadot and David Hasselhoof\"},\n",
    "    {\"role\": \"user\", \"content\": \"Dog\"}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 6: Exploring API parameters\n",
    "\n",
    "The Chat Completion API has a number of parameters that can be used to control the output of the model. \n",
    "\n",
    "In this example we will explore the following parameters:\n",
    "- `temperature` - Controls the randomness of the model. Lower values make the model more deterministic and higher values make the model more random.\n",
    "- `top_p` - Controls the diversity of the model. Lower values make the model more deterministic and higher values make the model more random.\n",
    "\n",
    "Let's explore the results we get when we make the model more deterministic and more random (or creative).\n",
    "\n",
    "We will use the same prompt for both examples based on the last example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌───────────────────────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 6.1: Generate Dog names more deterministically│\u001b[0m\n",
      "\u001b[1m└───────────────────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "Suggest three names for an animal that is a superhero.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Cat\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Cat Damon, Pawsley Snipes and Audrey Hepurrn\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Dog\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Bark Kent, Captain Canine and Wonder Woof\n",
      "\u001b[3mLikely you'll get the same response most of the time.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 6.1: Generate Dog names more deterministically\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "\n",
    "prompt_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Suggest three names for an animal that is a superhero.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Cat\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Cat Damon, Pawsley Snipes and Audrey Hepurrn\"},\n",
    "    {\"role\": \"user\", \"content\": \"Dog\"}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type, temperature=0, top_p=0)\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])\n",
    "italic(\"Likely you'll get the same response most of the time.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌────────────────────────────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 6.2: Generate Dog names more randomly or creatively│\u001b[0m\n",
      "\u001b[1m└────────────────────────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "Suggest three names for an animal that is a superhero.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Cat\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Cat Damon, Pawsley Snipes and Audrey Hepurrn\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Dog\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Ace Barkman, Blu Thunder Hounderson, Fido ElectroDasher\n",
      "\u001b[3mMore likely you'll get a different response each time.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 6.2: Generate Dog names more randomly or creatively\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "\n",
    "prompt_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Suggest three names for an animal that is a superhero.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Cat\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Cat Damon, Pawsley Snipes and Audrey Hepurrn\"},\n",
    "    {\"role\": \"user\", \"content\": \"Dog\"}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type, temperature=2, top_p=1)\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])\n",
    "italic(\"More likely you'll get a different response each time.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "- Example X: Specify Output Formats\n",
    "- Example X: Grounding\n",
    "- Example X: Auto Validation\n",
    "- Example X: Retrieval Augmented Generation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
