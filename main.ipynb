{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Before we can start having fun, let's setup the key libraries and functions we'll need. These will allow us to:\n",
    "- Call OpenAI's API\n",
    "- Call Bing's API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv\n",
    "%pip install pprintpp\n",
    "%pip install openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Variables\n",
    "\n",
    "Create an `.env` file in the root directory of this project. It should contain the following variables:\n",
    "\n",
    "```env\n",
    "BING_SEARCH_V7_SUBSCRIPTION_KEY=\"<your key here>\"\n",
    "BING_SEARCH_V7_ENDPOINT=\"https://api.bing.microsoft.com/\"\n",
    "OPENAI_KEY=\"<your openai key>\"\n",
    "OPENAI_AZURE_KEY=\"<your azure openai key>\"\n",
    "OPENAI_AZURE_BASE_URL=\"<your azure openai endpoint>\"\n",
    "OPENAI_AZURE_API_VERSION=\"2023-05-15\"\n",
    "OPENAI_AZURE_CHAT_COMPLETION_DEPLOYMENT_NAME=\"<your azure openai deployment name for gpt 3.5 or gpt 4>\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load environment variables\n",
    "import os\n",
    "from pprint import pprint\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create helper functions\n",
    "These are helper functions that will allow us to call the APIs and get the results we need.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Search for content using Bing Search using `bing_search`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function returns search results via Bing Search API\n",
    "def bing_search(query):\n",
    "    # Add your Bing Search V7 subscription key and endpoint to your environment variables.\n",
    "    subscription_key = os.environ[\"BING_SEARCH_V7_SUBSCRIPTION_KEY\"]    \n",
    "    endpoint = os.environ[\"BING_SEARCH_V7_ENDPOINT\"] \n",
    "\n",
    "    # Ensure that the subscription key & endpoint have been set, else throw an error.\n",
    "    if not subscription_key or not endpoint:\n",
    "        raise Exception(\"Set your environment variables for your subscription key and endpoint.\")\n",
    "\n",
    "    # Add a trailing slash to the endpoint if needed\n",
    "    if endpoint[-1] != \"/\":\n",
    "        endpoint = endpoint + \"/\"\n",
    "    endpoint = endpoint + \"v7.0/search\"\n",
    "\n",
    "\n",
    "    # Construct a request\n",
    "    mkt = \"en-US\"\n",
    "    params = { \"q\": query, \"mkt\": mkt }\n",
    "    headers = { \"Ocp-Apim-Subscription-Key\": subscription_key }\n",
    "\n",
    "    # Call the API\n",
    "    try:\n",
    "        response = requests.get(endpoint, headers=headers, params=params)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        search_results = response.json()\n",
    "    except Exception as ex:\n",
    "        raise ex\n",
    "    \n",
    "    return search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   {   'dateLastCrawled': '2023-06-26T02:04:00.0000000Z',\n",
      "        'deepLinks': [...],\n",
      "        'displayUrl': 'https://www.microsoft.com/en-us',\n",
      "        'id': 'https://api.bing.microsoft.com/api/v7/#WebPages.0',\n",
      "        'isFamilyFriendly': True,\n",
      "        'isNavigational': True,\n",
      "        'language': 'en',\n",
      "        'name': 'Microsoft – Cloud, Computers, Apps & Gaming',\n",
      "        'snippet': 'Explore Microsoft products and services for your home or business. Shop '\n",
      "                   'Surface, Microsoft 365, Xbox, Windows, Azure, and more. Find downloads and get '\n",
      "                   'support.',\n",
      "        'url': 'https://www.microsoft.com/en-us/'},\n",
      "    {   'dateLastCrawled': '2023-06-25T15:14:00.0000000Z',\n",
      "        'displayUrl': 'https://support.microsoft.com',\n",
      "        'id': 'https://api.bing.microsoft.com/api/v7/#WebPages.1',\n",
      "        'isFamilyFriendly': True,\n",
      "        'isNavigational': False,\n",
      "        'language': 'en',\n",
      "        'name': 'Microsoft Support',\n",
      "        'searchTags': [...],\n",
      "        'snippet': 'Microsoft support is here to help you with Microsoft products. Find how-to '\n",
      "                   'articles, videos, and training for Microsoft 365, Windows, Surface, and more.',\n",
      "        'url': 'https://support.microsoft.com/en-us'}]\n"
     ]
    }
   ],
   "source": [
    "# Perform a test search for the word \"Microsoft\"\n",
    "result = bing_search(\"Microsoft\")\n",
    "# Print the first 2 results within the JSON response.\n",
    "pprint(result[\"webPages\"][\"value\"][0:2], indent=4, width=100, depth=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Pretty Prining functions:\n",
    "\n",
    "    - `bold` - Print text in bold\n",
    "    - `wrap` - Wraps text with a default width of 100 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTesting the bold functionality.\u001b[0m\n",
      "\u001b[3mTesting the italic functionality.\u001b[0m\n",
      "The quick\n",
      "brown fox\n",
      "jumped\n",
      "over the\n",
      "lazy dog.\n",
      "\u001b[1m\n",
      "\n",
      "┌───────┐\u001b[0m\n",
      "\u001b[1m│Heading│\u001b[0m\n",
      "\u001b[1m└───────┘\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "def bold(text):\n",
    "    print(f'\\033[1m{text}\\033[0m')\n",
    "\n",
    "# Testing the bold function\n",
    "bold(\"Testing the bold functionality.\")\n",
    "\n",
    "def italic(text):\n",
    "    print(f'\\033[3m{text}\\033[0m')\n",
    "\n",
    "# Testing the italic function\n",
    "italic(\"Testing the italic functionality.\")\n",
    "\n",
    "def wrap(text, line_length=100):\n",
    "    for line in text.split('\\n'):\n",
    "        wrapper = textwrap.TextWrapper(width=line_length)\n",
    "        word_list = wrapper.wrap(text=line)\n",
    "\n",
    "        # Print each line\n",
    "        for l in word_list:\n",
    "            print(l)\n",
    "\n",
    "# Testing the wrap function\n",
    "wrap(\"The quick brown fox jumped over the lazy dog.\", 10)\n",
    "\n",
    "def box(text):    \n",
    "    bold(f'\\n\\n┌{\"─\" * len(text)}┐')\n",
    "    bold(f'│{text}│')\n",
    "    bold(f'└{\"─\" * len(text)}┘')\n",
    "\n",
    "# Testing the box function\n",
    "box(\"Heading\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Message helper functions: OpenAI's Chat Completions expects messages in the following format:\n",
    "    ```python\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who's there?\"}\n",
    "    ]\n",
    "    ```\n",
    "    To assist with this, we have the following functions:\n",
    "    \n",
    "    - `validate_message` - Validates that a message is in the expected format.\n",
    "    - `print_messages` - Prints messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messages are valid!\n",
      "Messages are invalid because:\n",
      "Each message should be a dictionary\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "You are a helpful assistant.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Knock knock.\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Who's there?\n"
     ]
    }
   ],
   "source": [
    "def validate_messages(messages):\n",
    "    # Define the acceptable roles\n",
    "    valid_roles = [\"system\", \"user\", \"assistant\"]\n",
    "\n",
    "    # Check if messages is a list\n",
    "    if not isinstance(messages, list):\n",
    "        raise TypeError(\"Input should be a list\")\n",
    "\n",
    "    # Iterate over the list of messages\n",
    "    for message in messages:\n",
    "        # Check if message is a dictionary\n",
    "        if not isinstance(message, dict):\n",
    "            raise TypeError(\"Each message should be a dictionary\")\n",
    "\n",
    "        # Check if the necessary keys exist in the dictionary\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            raise ValueError(\"Each message should have 'role' and 'content' keys\")\n",
    "\n",
    "        # Check if role is valid\n",
    "        if message[\"role\"] not in valid_roles:\n",
    "            raise ValueError(f\"Role should be one of {valid_roles}\")\n",
    "\n",
    "    # If all messages pass the checks, return True\n",
    "    return True\n",
    "\n",
    "# Test valid messages\n",
    "if validate_messages([\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Who's there?\"}\n",
    "]):\n",
    "    print(\"Messages are valid!\")\n",
    "\n",
    "# Test invalid messages\n",
    "try:\n",
    "    validate_messages([\n",
    "        \"You are a helpful assistant.\",\n",
    "    ])\n",
    "except Exception as ex:    \n",
    "    print(\"Messages are invalid because:\")\n",
    "    print(ex)\n",
    "\n",
    "def print_messages(messages):\n",
    "    # Validate the messages first\n",
    "    if validate_messages(messages):\n",
    "        # Iterate over the messages and print each one in the desired format\n",
    "        for message in messages:                        \n",
    "            bold(f'\\n[{message[\"role\"]}]:')\n",
    "            wrap(message[\"content\"])\n",
    "\n",
    "# Test the print_messages function\n",
    "print_messages([\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Who's there?\"}\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Helper message to call the ChatCompletions endpoint (direct or via azure) using `perform_chat_completion`. \n",
    "    ***Note:*** Can call azure OR openai directly based on the type parameter. Defaults to openai.\n",
    "\n",
    "    This function has the following parameters:\n",
    "\n",
    "    | Parameter | Description | Is Required | Default Value |\n",
    "    | --- | --- | --- | --- |\n",
    "    | `messages` | The messages to send to the API. | Yes | N/A |\n",
    "    | `type` | The type of API to call. Can be `openai` or `azure`. | No | `openai` |\n",
    "    | `temperature` | What temperature to use for the API call. A value between 0 and 2 | No | `0` |\n",
    "    | `top_p` | What top_p to use for the API call. A value between 0 and 1 | No | `1` |\n",
    "    | `max_tokens` | What max_tokens to use for the API call. A value between 1 and 4096 | No | `2048` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# This function calls the OpenAI (or Azure OpenAI)'s completion endpoint\n",
    "def perform_chat_completion(messages, type=\"openai\", temperature=0, top_p=0.5, max_tokens=2048):\n",
    "    # perform checks else raise exception\n",
    "    if type != 'openai' and type != 'azure':\n",
    "        raise Exception(\"type must be either openai or azure\")\n",
    "    \n",
    "    validate_messages(messages)\n",
    "    \n",
    "    if temperature < 0 or temperature > 2:\n",
    "        raise Exception(\"temperature must be between 0 and 2\")\n",
    "    \n",
    "    if top_p < 0 or top_p > 1:\n",
    "        raise Exception(\"top_p must be between 0 and 1\")\n",
    "\n",
    "    if max_tokens < 1 or max_tokens > 4096:\n",
    "        raise Exception(\"max_tokens must be between 1 and 2048\")\n",
    "\n",
    "\n",
    "    # check if type is openai or azure\n",
    "    if type == \"openai\":        \n",
    "        if not os.environ[\"OPENAI_KEY\"]:\n",
    "            raise Exception(\"Set your OPENAI_KEY environment variable.\")\n",
    "        \n",
    "        import openai        \n",
    "        openai.api_type = \"openai\"\n",
    "        openai.api_version = None\n",
    "        openai.api_base = \"https://api.openai.com/v1/\"\n",
    "        openai.api_key = os.environ[\"OPENAI_KEY\"]\n",
    "            \n",
    "\n",
    "        try:\n",
    "            results = openai.ChatCompletion.create(\n",
    "                model='gpt-3.5-turbo',\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                top_p=top_p,\n",
    "                max_tokens=max_tokens\n",
    "            )\n",
    "        except Exception as ex:\n",
    "            raise ex\n",
    "    else:\n",
    "        if not os.environ[\"OPENAI_AZURE_KEY\"]:\n",
    "            raise Exception(\"Set your OPENAI_AZURE_KEY environment variable.\")\n",
    "        if not os.environ[\"OPENAI_AZURE_BASE_URL\"]:\n",
    "            raise Exception(\"Set your OPENAI_AZURE_BASE_URL environment variable.\")\n",
    "        if not os.environ[\"OPENAI_AZURE_API_VERSION\"]:\n",
    "            raise Exception(\"Set your OPENAI_AZURE_API_VERSION environment variable.\")\n",
    "        if not os.environ[\"OPENAI_AZURE_CHAT_COMPLETION_DEPLOYMENT_NAME\"]:\n",
    "            raise Exception(\"Set your OPENAI_AZURE_CHAT_COMPLETION_DEPLOYMENT_NAME environment variable.\")\n",
    "                \n",
    "        import openai\n",
    "        openai.api_type = 'azure'\n",
    "        openai.api_version = os.environ[\"OPENAI_AZURE_API_VERSION\"]\n",
    "        openai.api_base = os.environ[\"OPENAI_AZURE_BASE_URL\"]\n",
    "        openai.api_key = os.environ[\"OPENAI_AZURE_KEY\"]\n",
    "        \n",
    "        try:\n",
    "            results = openai.ChatCompletion.create(\n",
    "                deployment_id=os.environ[\"OPENAI_AZURE_CHAT_COMPLETION_DEPLOYMENT_NAME\"],\n",
    "                messages=messages,\n",
    "                temperature=temperature,\n",
    "                top_p=top_p,\n",
    "                max_tokens=max_tokens\n",
    "            )\n",
    "        except Exception as ex:\n",
    "            raise ex\n",
    "        \n",
    "    return results        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌──────────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Call Chat Completions endoint using OpenAI│\u001b[0m\n",
      "\u001b[1m└──────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "You are a helpful assistant.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Hi there.\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Note: You can skip this step if you are using Azure OpenAI Service\n",
    "box(\"Call Chat Completions endoint using OpenAI\")\n",
    "completion_message_request = [\n",
    "   {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "   {\"role\": \"user\", \"content\": \"Hi there.\"}\n",
    "]\n",
    "print_messages(completion_message_request)\n",
    "chat_completion = perform_chat_completion(completion_message_request, \"openai\")\n",
    "print_messages([chat_completion[\"choices\"][0][\"message\"]])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌──────────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Call Chat Completions endoint using  Azure│\u001b[0m\n",
      "\u001b[1m└──────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "You are a helpful assistant.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Hi there.\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Note: You can skip this step if you are using OpenAI's API\n",
    "box(\"Call Chat Completions endoint using  Azure\")\n",
    "completion_message_request = [\n",
    "   {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "   {\"role\": \"user\", \"content\": \"Hi there.\"}\n",
    "]\n",
    "print_messages(completion_message_request)\n",
    "chat_completion = perform_chat_completion(completion_message_request, \"azure\")\n",
    "print_messages([chat_completion[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Engineering "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Simple conversational scenarios\n",
    "\n",
    "The following code snippet shows the most basic way to use the ChatGPT and GPT-4 models with the Chat Completion API. \n",
    "\n",
    "In this example we ask the model to complete the following conversation:\n",
    "```log\n",
    "system: You are a helpful assistant.\n",
    "user: Who were the founders of Microsoft?\n",
    "assistant:\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌───────────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 1: Simple conversational scenarios│\u001b[0m\n",
      "\u001b[1m└───────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "You are a helpful assistant.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Who were the founders of Microsoft?\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "The founders of Microsoft are Bill Gates and Paul Allen.\n"
     ]
    }
   ],
   "source": [
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "prompt_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Who were the founders of Microsoft?\"}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "box(\"Scenario 1: Simple conversational scenarios\")\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the code above, the chat completion API expects messages to be in the following format:   \n",
    "```json\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Knock knock.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Who's there?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Orange.\"},\n",
    "]\n",
    "```\n",
    "\n",
    "Depending on the role you should use the following values:\n",
    "| Role | Purpose | Explaination | Example |\n",
    "| --- | --- | --- | --- |\n",
    "| `system` | Provide some context and/or instructions to the model. | The system message is included at the beginning of the prompt and is used to prime the model and you can include a variety of information in the system message including: <br> - A brief description of the assistant <br> - The personality of the assistant <br> - Instructions for the assistant <br> - Data or information needed for the model | `{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}` |\n",
    "| `user` | A question/message for the model to actually respond to. | After the system message, you can include a series of messages between the user and the assistant. You denote who the message is from by setting the role to user or assistant. | `{\"role\": \"user\", \"content\": \"Knock knock.\"}` |\n",
    "\n",
    "\n",
    "\n",
    "**⚠️ You might be wondering how this is different from the previous models.**\n",
    "\n",
    "Unlike previous GPT-3 models, the ChatGPT model is specifically designed to be a conversational interface. The conversational nature of the model makes it easier to interact with and to \u000btake advantage of the full power of its capabilities.\n",
    "\n",
    "Previous models were text-in and text-out (i.e., they accepted a prompt string and returned a completion to append to the prompt).\n",
    "\n",
    "The ChatGPT model is conversation-in and message-out. (i.e., it expects a prompt string that is formatted in a specific chat-like transcript format and returns a completion that represents a model-written message in the chat)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Non conversational scenarios\n",
    "\n",
    "While the Chat Completion API is optimized to work with multi-turn conversations, it also can be used for non chat scenarios. \n",
    "\n",
    "This example is set as follows:\n",
    "| Role | Explanation |\n",
    "| --- | --- | \n",
    "| `system` | You are an assistant designed to summarise this non-fiction books. Users will paste in a name of a book and you will respond with a short summary. Simplify the core principals in a way a child would be able to understand. | \n",
    "| `user` | Thinking, Fast and Slow by Daniel Kahneman |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌────────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 2: Non conversational scenarios│\u001b[0m\n",
      "\u001b[1m└────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "You are an assistant designed to summarise this non-fiction books. Users will paste in a name of a\n",
      "book and you will respond with a short summary. Simplify the core principals in a way a child would\n",
      "be able to understand.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Thinking, Fast and Slow by Daniel Kahneman\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "\"Thinking, Fast and Slow\" is a book about how our brains work. It explains that we have two\n",
      "different ways of thinking: fast and slow. Fast thinking is when we make quick decisions without\n",
      "really thinking about them. Slow thinking is when we take our time and really think things through.\n",
      "The book also talks about how our brains can sometimes trick us into making bad decisions, and how\n",
      "we can learn to make better decisions by being aware of these tricks.\n"
     ]
    }
   ],
   "source": [
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "prompt_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are an assistant designed to summarise this non-fiction books. Users will paste in a name of a book and you will respond with a short summary. Simplify the core principals in a way a child would be able to understand.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Thinking, Fast and Slow by Daniel Kahneman\"}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "box(\"Scenario 2: Non conversational scenarios\")\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3: Role Prompting or Personas\n",
    "\n",
    "Here lets explore the `Be specific` and `Be descriptive` best practices listed at https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/prompt-engineering#best-practices.\n",
    "\n",
    "- `Be Specific`: Leave as little to interpretation as possible. Restrict the operational space.\n",
    "- `Be Descriptive`: Use analogies.\n",
    "\n",
    "In this example we will show how being specific and descriptive can help us get better results. \n",
    "\n",
    "**Scenario 3.1: Basic prompt**\n",
    "\n",
    "| Role | Explanation |\n",
    "| --- | --- |\n",
    "| `user` | What is 1000*1000/20*50? |\n",
    "\n",
    "**Scenario 3.2: Better prompt using Role Prompting**\n",
    "\n",
    "| Role | Explanation |\n",
    "| --- | --- |\n",
    "| `system` | Assume you are a math teacher and you are going to teach Order Of Operations Activities (BODMAS, BIMDAS, PEMDAS, GEMS & More) to your students. |\n",
    "| `user` | What is 1000*1000/20*50? |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌──────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 3.1: Basic prompt│\u001b[0m\n",
      "\u001b[1m└──────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "What is 1000*1000/20*50?\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "1000*1000/20*50 = 50,000\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 3.1: Basic prompt\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "prompt_messages = [    \n",
    "    {\"role\": \"user\", \"content\": \"What is 1000*1000/20*50?\"}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌────────────────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 3.2: Better prompt using Role Prompting│\u001b[0m\n",
      "\u001b[1m└────────────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Assume you are a math teacher and you are going to teach PEMDAS (Parentheses, Exponents,\n",
      "Multiplication and Division from left to right, and Addition and Subtraction from left to right) to\n",
      "your students. What is 1000*1000/20*50?\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "To solve this problem using PEMDAS, we need to follow the order of operations:\n",
      "1. Parentheses (none)\n",
      "2. Exponents (none)\n",
      "3. Multiplication and Division from left to right:\n",
      "1000 * 1000 = 1,000,000\n",
      "1,000,000 / 20 = 50,000\n",
      "50,000 * 50 = 2,500,000\n",
      "4. Addition and Subtraction from left to right (none)\n",
      "Therefore, 1000*1000/20*50 = 2,500,000.\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 3.2: Better prompt using Role Prompting\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "prompt_messages = [    \n",
    "    {\"role\": \"user\", \"content\": \"Assume you are a math teacher and you are going to teach PEMDAS (Parentheses, Exponents, Multiplication and Division from left to right, and Addition and Subtraction from left to right) to your students. What is 1000*1000/20*50?\"}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 4: Providing instructions to get expected results\n",
    "\n",
    "To ensure the model provides the expected results, you can provide instructions to the model within the system message.\n",
    "\n",
    "In this example, show the difference beteen providing instructions and not providing instructions. We will use the same prompt for both examples, but the system message will be different.\n",
    "\n",
    "**Scenario 4.1: No instructions**\n",
    "\n",
    "| Role | Explanation |\n",
    "| --- | --- |\n",
    "| `system` | You are an assistant designed to summarise this non-fiction books. Users will paste in a name of a book and you will respond with a short summary. Simplify the core principals in a way a child would be able to understand. |\n",
    "| `user` | How to build your Technology Strategy by Rohit Lakhanpal |\n",
    "\n",
    "**Scenario 4.2: With instructions**\n",
    "\n",
    "| Role | Explanation |\n",
    "| --- | --- |\n",
    "| `system` | You are an assistant designed to summarise this non-fiction books. Users will paste in a name of a book and you will respond with a short summary. Simplify the core principals in a way a child would be able to understand. <br> <br> **Instructions:** <br> - If you don't know about the book, say \"I don't know\". <br> - Don't make up information. |\n",
    "| `user` | How to build your Technology Strategy by Rohit Lakhanpal |\n",
    "\n",
    "\n",
    "**Note**: No book called \"How to build your Technology Strategy\" by \"Rohit Lakhanpal\" exists. The model will make up information if you don't provide instructions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌─────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 4.1: No instructions│\u001b[0m\n",
      "\u001b[1m└─────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "You are an assistant designed to summarise this non-fiction books. Users will paste in a name of a\n",
      "book and you will respond with a short summary. Simplify the core principals in a way a child would\n",
      "be able to understand.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "How to build your Technology Strategy by Rohit Lakhanpal\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "This book is about making a plan for using technology in a smart way. It helps you think about what\n",
      "you want to achieve with technology and how to make it happen. It's like making a map to get to your\n",
      "destination, but for technology!\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 4.1: No instructions\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "system_message = \"You are an assistant designed to summarise this non-fiction books. Users will paste in a name of a book and you will respond with a short summary. Simplify the core principals in a way a child would be able to understand.\"\n",
    "book = \"How to build your Technology Strategy by Rohit Lakhanpal\"\n",
    "prompt_messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": book}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌───────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 4.2: With instructions│\u001b[0m\n",
      "\u001b[1m└───────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "You are an assistant designed to summarise this non-fiction books. Users will paste in a name of a\n",
      "book and you will respond with a short summary. Simplify the core principals in a way a child would\n",
      "be able to understand.\n",
      "#Instructions:\n",
      "- If you don't know about the book, say \"I don't know\".\n",
      "- Don't make up information.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "How to be a Tech Stragist by Rohit Lakhanpal\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 4.2: With instructions\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "system_message = \"\"\"You are an assistant designed to summarise this non-fiction books. Users will paste in a name of a book and you will respond with a short summary. Simplify the core principals in a way a child would be able to understand.\n",
    "\n",
    "#Instructions:\n",
    "- If you don't know about the book, say \"I don't know\". \n",
    "- Don't make up information.\n",
    "\"\"\"\n",
    "prompt_messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": \"How to be a Tech Stragist by Rohit Lakhanpal\"}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen in example above, when you don't provide instructions, the model will make up information. This is known as `hallucination`. To combat this, we used the system message to provide instructions to the model. This is part of the best practice known as `Giving the model an out`.\n",
    "\n",
    "**Give the model an out**: It can sometimes be helpful to give the model an alternative path if it is unable to complete the assigned task. For example, when asking a question over a piece of text you might include something like `respond with 'not found' if the answer is not present`. This can help the model avoid generating false responses.\n",
    "\n",
    "Learn more at https://learn.microsoft.com/en-us/azure/cognitive-services/openai/concepts/prompt-engineering#best-practices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 5: Zero Shot, One Shot, Few Shot\n",
    "\n",
    "In this example we will show how to use the `Zero Shot`, `One Shot` and `Few Shot` capabilities of the Chat Completion API. \n",
    "\n",
    "**Scenario 5.1: Zero Shot**\n",
    "\n",
    "Only the command and the unsolved input is provided to the model.\n",
    "\n",
    "| Role | Explanation |\n",
    "| --- | --- |\n",
    "| `system` | Suggest three names for an animal that is a superhero. |\n",
    "| `user` | Dog |\n",
    "\n",
    "\n",
    "**Scenario 5.2: One Shot**\n",
    "\n",
    "One example is provided to the model before an unsolved problem is asked.\n",
    "\n",
    "| Role | Explanation |\n",
    "| --- | --- |\n",
    "| `system` | Suggest three names for an animal that is a superhero. |\n",
    "| `user` | Cat |\n",
    "| `assistant` | Cat Damon, Pawsley Snipes and Audrey Hepurrn |\n",
    "| `user` | Dog |\n",
    "\n",
    "\n",
    "**Scenario 5.3: Few Shot**\n",
    "\n",
    "Few solved examples are provided to the model before an unsolved problem is asked.\n",
    "\n",
    "| Role | Explanation |\n",
    "| --- | --- |\n",
    "| `system` | Suggest three names for an animal that is a superhero. |\n",
    "| `user` | Cat |\n",
    "| `assistant` | Cat Damon, Pawsley Snipes and Audrey Hepurrn |\n",
    "| `user` | Horse |\n",
    "| `assistant` | Neigh-talie Portman, Gallop Gadot and David Hasselhoof |\n",
    "| `user` | Dog |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌────────────────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 5.1: Generate Dog named using Zero Shot│\u001b[0m\n",
      "\u001b[1m└────────────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "Suggest three names for an animal that is a superhero.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Dog\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "1. Superpup\n",
      "2. Mighty Mutt\n",
      "3. Captain Canine\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 5.1: Generate Dog named using Zero Shot\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "\n",
    "prompt_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Suggest three names for an animal that is a superhero.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Dog\"}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌───────────────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 5.2: Generate Dog named using One Shot│\u001b[0m\n",
      "\u001b[1m└───────────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "Suggest three names for an animal that is a superhero.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Cat\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Cat Damon, Pawsley Snipes and Audrey Hepurrn\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Dog\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Bark Kent, Captain Canine and Wonder Woof\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 5.2: Generate Dog named using One Shot\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "\n",
    "prompt_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Suggest three names for an animal that is a superhero.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Cat\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Cat Damon, Pawsley Snipes and Audrey Hepurrn\"},\n",
    "    {\"role\": \"user\", \"content\": \"Dog\"}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌───────────────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 5.3: Generate Dog named using Few Shot│\u001b[0m\n",
      "\u001b[1m└───────────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "Suggest three names for an animal that is a superhero.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Cat\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Cat Damon, Pawsley Snipes and Audrey Hepurrn\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Horse\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Neigh-talie Portman, Gallop Gadot and David Hasselhoof\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Dog\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Bark Kent, Wonder Pug and Captain Canine\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 5.3: Generate Dog named using Few Shot\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "\n",
    "prompt_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Suggest three names for an animal that is a superhero.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Cat\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Cat Damon, Pawsley Snipes and Audrey Hepurrn\"},    \n",
    "    {\"role\": \"user\", \"content\": \"Horse\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Neigh-talie Portman, Gallop Gadot and David Hasselhoof\"},\n",
    "    {\"role\": \"user\", \"content\": \"Dog\"}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 6: Exploring API parameters\n",
    "\n",
    "The Chat Completion API has a number of parameters that can be used to control the output of the model. \n",
    "\n",
    "In this example we will explore the following parameters:\n",
    "\n",
    "- `temperature`: \n",
    "\n",
    "    Controls the randomness of the model. Lower values make the model more deterministic and higher values make the model more random.\n",
    "    At zero the model becomes deterministic (default: 0.3 – 0.7). Lower values are better for \"accuracy\", higher values better for \"creativity\".\n",
    "\n",
    "- `top_p`:\n",
    "\n",
    "    Controls the diversity via nucleus sampling. When set to 0.5 means half of all likelihood-weighted options are considered (default: 1). Can act as a filter for unlikely completions.\n",
    "\n",
    "Let's explore the results we get when we make the model more deterministic v/s more random (or creative). We will use the same prompt for both examples based on the last example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌───────────────────────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 6.1: Generate Dog names more deterministically│\u001b[0m\n",
      "\u001b[1m└───────────────────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "Suggest three names for an animal that is a superhero.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Cat\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Cat Damon, Pawsley Snipes and Audrey Hepurrn\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Dog\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Bark Kent, Captain Canine and Wonder Woof\n",
      "\u001b[3mLikely you'll get the same response most of the time.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 6.1: Generate Dog names more deterministically\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "\n",
    "prompt_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Suggest three names for an animal that is a superhero.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Cat\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Cat Damon, Pawsley Snipes and Audrey Hepurrn\"},\n",
    "    {\"role\": \"user\", \"content\": \"Dog\"}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type, temperature=0, top_p=0)\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])\n",
    "italic(\"Likely you'll get the same response most of the time.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌────────────────────────────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 6.2: Generate Dog names more randomly or creatively│\u001b[0m\n",
      "\u001b[1m└────────────────────────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "Suggest three names for an animal that is a superhero.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Cat\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Cat Damon, Pawsley Snipes and Audrey Hepurrn\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Dog\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Ace Barkman, Blu Thunder Hounderson, Fido ElectroDasher\n",
      "\u001b[3mMore likely you'll get a different response each time.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 6.2: Generate Dog names more randomly or creatively\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "\n",
    "prompt_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Suggest three names for an animal that is a superhero.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Cat\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Cat Damon, Pawsley Snipes and Audrey Hepurrn\"},\n",
    "    {\"role\": \"user\", \"content\": \"Dog\"}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type, temperature=2, top_p=1)\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])\n",
    "italic(\"More likely you'll get a different response each time.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 7: Specify output formats\n",
    "\n",
    "You can specify output formats using the system message or in some cases, it can be inferred via the one-shot or few-shot examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌──────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 7: Specify output formats│\u001b[0m\n",
      "\u001b[1m└──────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[system]:\u001b[0m\n",
      "You are an assistant designed to extract entities from text. Users will paste in a string of text\n",
      "and you will respond with entities you've extracted from the text as a JSON object. Here's an\n",
      "example of your output format:\n",
      "{\n",
      "   \"name\": \"\",\n",
      "   \"company\": \"\",\n",
      "   \"phone_number\": \"\"\n",
      "}\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Hello. My name is Robert Smith. I’m calling from Contoso Insurance, Delaware. My colleague mentioned\n",
      "that you are interested in learning about our comprehensive benefits policy. Could you give me a\n",
      "call back at (555) 346-9322 when you get a chance so we can go over the benefits?\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "{\n",
      "   \"name\": \"Robert Smith\",\n",
      "   \"company\": \"Contoso Insurance\",\n",
      "   \"phone_number\": \"(555) 346-9322\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 7: Specify output formats\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "system_message = \"\"\"\n",
    "You are an assistant designed to extract entities from text. Users will paste in a string of text and you will respond with entities you've extracted from the text as a JSON object. Here's an example of your output format:\n",
    "{\n",
    "   \"name\": \"\",\n",
    "   \"company\": \"\",\n",
    "   \"phone_number\": \"\"\n",
    "}\n",
    "\"\"\"\n",
    "prompt_messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": \"Hello. My name is Robert Smith. I’m calling from Contoso Insurance, Delaware. My colleague mentioned that you are interested in learning about our comprehensive benefits policy. Could you give me a call back at (555) 346-9322 when you get a chance so we can go over the benefits?\"}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 8: Chain of thought reasoning\n",
    "\n",
    "Another powerful technique for improving the reliability of answers is to prompt the model to gradually reason out the answer rather than jumping immediately to the final answer. By 'thinking aloud' the model can be far more likely to arrive at the correct answer.\n",
    "\n",
    "This technique called Chain-of-Thought, actually only discovered recently , is a super powerful technique, not only can it be used to provide model explainability (where sometimes GPT-3 is seen as a blackbox) but it can help the model reason and arrive at a desired output by simply just telling the model to think step by step. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌────────────────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 8.1: Without Chain of thought reasoning│\u001b[0m\n",
      "\u001b[1m└────────────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Brain Teaser:\n",
      "What is the annual water demand of a single-family household containing four people at home an\n",
      "average of 200 days per year and using an average of 100 litres of water daily?\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "The annual water demand would be 8,000 litres (100 litres per day x 4 people x 200 days).\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 8.1: Without Chain of thought reasoning\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "query = \"\"\"Brain Teaser: \n",
    "What is the annual water demand of a single-family household containing four people at home an average of 200 days per year and using an average of 100 litres of water daily?\n",
    "\"\"\"\n",
    "prompt_messages = [\n",
    "    {\"role\": \"user\", \"content\": query}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌─────────────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 8.2: With Chain of thought reasoning│\u001b[0m\n",
      "\u001b[1m└─────────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Brain Teaser:\n",
      "What is the annual water demand of a single-family household containing four people at home an\n",
      "average of 200 days per year and using an average of 100 litres of water daily?\n",
      "Let's think step by step and explain the calculation step by step.\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Step 1: Calculate the total number of days the household uses water in a year.\n",
      "The household is at home for 200 days per year, so the total number of days they use water is 200.\n",
      "Step 2: Calculate the total amount of water used by the household in a year.\n",
      "The household uses an average of 100 litres of water daily, so the total amount of water used in a\n",
      "year is:\n",
      "100 litres/day x 200 days = 20,000 litres\n",
      "Step 3: Divide the total amount of water used by the number of people in the household.\n",
      "There are four people in the household, so the annual water demand per person is:\n",
      "20,000 litres / 4 people = 5,000 litres/person\n",
      "Therefore, the annual water demand of a single-family household containing four people at home an\n",
      "average of 200 days per year and using an average of 100 litres of water daily is 20,000 litres, or\n",
      "5,000 litres per person.\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 8.2: With Chain of thought reasoning\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "query = \"\"\"Brain Teaser: \n",
    "What is the annual water demand of a single-family household containing four people at home an average of 200 days per year and using an average of 100 litres of water daily?\n",
    "\n",
    "Let's think step by step and explain the calculation step by step.\n",
    "\"\"\"\n",
    "prompt_messages = [\n",
    "    {\"role\": \"user\", \"content\": query}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 9: Prompt Chaining\n",
    "\n",
    "Prompt chaining is a technique where you can chain multiple prompts together to get a desired output. Here we will modify the previous prompt and add a new prompt at the end to get a desired output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌───────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 9: Prompt Chaining│\u001b[0m\n",
      "\u001b[1m└───────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Brain Teaser:\n",
      "What is the annual water demand of a single-family household containing four people at home an\n",
      "average of 200 days per year and using an average of 100 litres of water daily?\n",
      "Let's think step by step and explain the calculation step by step.\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "Step 1: Calculate the total number of days the household uses water in a year.\n",
      "The household is at home for 200 days per year, so the total number of days they use water is 200.\n",
      "Step 2: Calculate the total amount of water used by the household in a year.\n",
      "The household uses an average of 100 litres of water daily, so the total amount of water used in a\n",
      "year is:\n",
      "100 litres/day x 200 days = 20,000 litres\n",
      "Step 3: Divide the total amount of water used by the number of people in the household.\n",
      "The household contains four people, so the annual water demand per person is:\n",
      "20,000 litres / 4 people = 5,000 litres/person\n",
      "Therefore, the annual water demand of a single-family household containing four people at home an\n",
      "average of 200 days per year and using an average of 100 litres of water daily is 20,000 litres, or\n",
      "5,000 litres per person.\n",
      "\u001b[1m\n",
      "[user]:\u001b[0m\n",
      "Therefore, the answer (number) is:\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "20,000 litres.\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 9: Prompt Chaining\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "query = \"\"\"Brain Teaser: \n",
    "What is the annual water demand of a single-family household containing four people at home an average of 200 days per year and using an average of 100 litres of water daily?\n",
    "\n",
    "Let's think step by step and explain the calculation step by step.\n",
    "\"\"\"\n",
    "response = \"\"\"\n",
    "Step 1: Calculate the total number of days the household uses water in a year.\n",
    "The household is at home for 200 days per year, so the total number of days they use water is 200.\n",
    "Step 2: Calculate the total amount of water used by the household in a year.\n",
    "The household uses an average of 100 litres of water daily, so the total amount of water used in a\n",
    "year is:\n",
    "100 litres/day x 200 days = 20,000 litres\n",
    "Step 3: Divide the total amount of water used by the number of people in the household.\n",
    "The household contains four people, so the annual water demand per person is:\n",
    "20,000 litres / 4 people = 5,000 litres/person\n",
    "Therefore, the annual water demand of a single-family household containing four people at home an\n",
    "average of 200 days per year and using an average of 100 litres of water daily is 20,000 litres, or\n",
    "5,000 litres per person.\n",
    "\"\"\"\n",
    "prompt_messages = [\n",
    "    {\"role\": \"user\", \"content\": query},\n",
    "    {\"role\": \"assistant\", \"content\": response},\n",
    "    {\"role\": \"user\", \"content\": \"Therefore, the answer (number) is:\"}\n",
    "]\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 10: Provide grounding context via Retrieval Augmented Generation\n",
    "\n",
    "If your use case relies on up-to-date, reliable information and is not purely a creative scenarios then one the most effective ways to provide reliable answers is to give the model data to draw its responses from grounding data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "\n",
      "┌─────────────────────────────────────────────────────────┐\u001b[0m\n",
      "\u001b[1m│Scenario 10: Grounding and Retrieval Augmented Generation│\u001b[0m\n",
      "\u001b[1m└─────────────────────────────────────────────────────────┘\u001b[0m\n",
      "\u001b[1m\n",
      "[assistant]:\u001b[0m\n",
      "To get a user's presence using Graph API, you need to use Delegated permissions [doc1].\n"
     ]
    }
   ],
   "source": [
    "box(\"Scenario 10: Grounding and Retrieval Augmented Generation\")\n",
    "type = \"azure\" # change this to \"openai\" if you are using OpenAI's APIs directly\n",
    "system_message = \"\"\"You are an AI assistant that answers technical questions about Azure based on the context provided.\n",
    "\n",
    "## Instructions\n",
    "- You should always leverage the retrieved documents when the user is seeking information or whenever retrieved documents could be potentially helpful, regardless of your internal knowledge or information.\n",
    "- You can leverage past responses and retrieved documents for generating relevant and interesting suggestions for the next user turn.\n",
    "- You can only issue references to the documents as citation examples below. You should **never generate** URLs or links apart from the ones provided in retrieved documents.\n",
    "- Retrieved documents may be incomplete or irrelevant. You don't make assumptions on the retrieved documents beyond strictly what's returned.\n",
    "- If the retrieved documents do not contain sufficient information to answer user message completely, you can only include **facts from the retrieved documents** and do not add any information by itself.\n",
    "- You can leverage information from multiple retrieved documents to respond **comprehensively**.\n",
    "- You **should always** reference factual statements to the search results.\n",
    "- If you are not sure, say \"I don't know\".\n",
    "\"\"\"\n",
    "user_shot_1 = \"\"\"\n",
    "What access does AOAI provide to OpenAI models?\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"retrieved_documents\": [\n",
    "    {\n",
    "      \"[doc1]\": {\n",
    "        \"title\": \"What is Azure OpenAI Service?\",\n",
    "        \"content\": \"Azure OpenAI Service provides REST API access to OpenAI's powerful language models including the GPT-3, Codex and Embeddings model series. These models can be easily adapted to your specific task including but not limited to content generation, summarization, semantic search, and natural language to code translation. Users can access the service through REST APIs, Python SDK, or our web-based interface in the Azure OpenAI Studio.\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"[doc2]\": {\n",
    "        \"title\": \"What is Azure Blob Storage?\",\n",
    "        \"content\": \"Azure Blob Storage is Microsoft's object storage solution for the cloud. Blob Storage is optimized for storing massive amounts of unstructured data. Unstructured data is data that doesn't adhere to a particular data model or definition, such as text or binary data.\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"[doc3]\": {\n",
    "        \"title\": \"What is requirement for access Azure storage?\",\n",
    "        \"content\": \"To access Azure Storage, you'll need an Azure subscription. If you don't already have a subscription, create a free account before you begin. All access to Azure Storage takes place through a storage account. For this quickstart, create a storage account using the Azure portal, Azure PowerShell, or Azure CLI. For help creating a storage account, see Create a storage account.\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"[doc4]\": {\n",
    "        \"title\": \"How to upload files to Azure Blob storage?\",\n",
    "        \"content\": \"You can upload files and directories to Blob storage by using the AzCopy v10 command-line utility.\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "assistant_shot_1 = \"\"\"\n",
    "Currently AOAI provides REST APIs, Python SDK, and web-based interface in the Azure OpenAI Studio to OpenAI's powerful language models [doc1].\n",
    "\"\"\"\n",
    "user_shot_2 = \"\"\"\n",
    "What is the deductible for the employee plan for a visit to Overlake in Bellevue?\n",
    "```json\n",
    "{\n",
    "  \"retrieved_documents\": [\n",
    "    {\n",
    "      \"[doc1]\": {\n",
    "        \"title\": \"How to calculate the deductible?\",\n",
    "        \"content\": \"Deductibles depend on whether you are in-network or out-of-network. In-network deductibles are $500 for employee and $1000 for family. Out-of-network deductibles are $1000 for employee and $2000 for family.\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"[doc2]\": {\n",
    "        \"title\": \"Is Overlake in-network?\",\n",
    "        \"content\": \"Overlake is in-network for the employee plan.\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"[doc3]\": {\n",
    "        \"title\": \"What is Overlake?\",\n",
    "        \"content\": \"Overlake is the name of the area that includes a park and ride near Bellevue.\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"[doc4]\": {\n",
    "        \"title\": \"What is the in-network list?\",\n",
    "        \"content\": \"In-network institutions include Overlake, Swedish and others in the region\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "assistant_shot_2 = \"\"\"\n",
    "In-network deductibles are $500 for employee and $1000 for family [doc1]. Overlake is in-network for the employee plan [doc2][doc4].\n",
    "\"\"\"\n",
    "user_question = \"\"\"\n",
    "I want to programatically get a user's presence using Graph API. Can this be done using Application permissions type or does it need Delegated permissions?\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"retrieved_documents\": [\n",
    "    {\n",
    "      \"[doc1]\": {\n",
    "        \"title\": \"title: Tutorial - Web app accesses Microsoft Graph as the user | Azure\",\n",
    "        \"content\": \"title: title: Tutorial - Web app accesses Microsoft Graph as the user | Azure\\ndescription: In this tutorial, you learn how to access data in Microsoft Graph for a signed-in user.\\nservices: microsoft-graph, app-service-web\\nauthor: rwike77\\nmanager: CelesteDG\\ndocument_link: https://github.com/MicrosoftDocs/azure-docs/blob/main/articles/app-service/includes/tutorial-connect-app-access-microsoft-graph-as-user/intro.md\\ntitle: Tutorial - Web app accesses Microsoft Graph as the user | Azure\\ndescription: In this tutorial, you learn how to access data in Microsoft Graph for a signed-in user.\\nservices: microsoft-graph, app-service-web\\nauthor: rwike77\\nmanager: CelesteDG\\nms.service: app-service\\nms.topic: include\\nms.workload: identity\\nms.date: 11/02/2021\\nms.author: ryanwi\\nms.reviewer: stsoneff\\nms.devlang: csharp, javascript\\nms.custom: azureday1\\nCustomer intent: As an application developer, I want to learn how to access data in Microsoft Graph for a signed-in user.\\nms.subservice: web-apps\\nLearn how to access Microsoft Graph from a web app running on Azure App Service.\\n:::image type=\\\"content\\\" alt-text=\\\"Diagram that shows accessing Microsoft Graph.\\\" source=\\\"../../media/scenario-secure-app-access-microsoft-graph/web-app-access-graph.svg\\\" border=\\\"false\\\":::\\nYou want to add access to Microsoft Graph from your web app and perform some action as the signed-in user. This section describes how to grant delegated permissions to the web app and get the signed-in user's profile information from Azure Active Directory (Azure AD).\\nIn this tutorial, you learn how to:\\n[!div class=\\\"checklist\\\"]\\nGrant delegated permissions to a web app.\\nCall Microsoft Graph from a web app for a signed-in user.\\n[!INCLUDE quickstarts-free-trial-note]\\nPrerequisites\\nA web application running on Azure App Service that has the App Service authentication/authorization module enabled.\\nGrant front-end access to call Microsoft Graph\\nNow that you've enabled authentication and authorization on your web app, the web app is registered with the Microsoft identity platform and is backed by an Azure AD application. In this step, you give the web app permissions to access Microsoft Graph for the user. (Technically, you give the web app's Azure AD application the permissions to access the Microsoft Graph Azure AD application for the user.)\\nIn the Azure portal menu, select Azure Active Directory or search for and select Azure Active Directory from any page.\\nSelect App registrations > Owned applications > View all applications in this directory. Select your web app name, and then select API permissions.\\nSelect Add a permission, and then select Microsoft APIs and Microsoft Graph.\\nSelect Delegated permissions, and then select User.Read from the list. Select Add permissions.\\nConfigure App Service to return a usable access token\\nThe web app now has the required permissions to access Microsoft Graph as the signed-in user. In this step, you configure App Service authentication and authorization to give you a usable access token for accessing Microsoft Graph. For this step, you need to add the User.Read scope for the downstream service (Microsoft Graph): https://graph.microsoft.com/User.Read.\\n[!IMPORTANT]\\nIf you don't configure App Service to return a usable access token, you receive a CompactToken parsing failed with error code: 80049217 error when you call Microsoft Graph APIs in your code.\\nAzure Resource Explorer\\nGo to Azure Resource Explorer and using the resource tree, locate your web app. The resource URL should be similar to https://resources.azure.com/subscriptions/subscriptionId/resourceGroups/SecureWebApp/providers/Microsoft.Web/sites/SecureWebApp20200915115914.\\nThe Azure Resource Explorer is now opened with your web app selected in the resource tree. At the top of the page, select Read/Write to enable editing of your Azure resources.\\nIn the left browser, drill down to config > authsettingsV2.\\nIn the authsettingsV2 view, select Edit. Find the login section of identityProviders -> azureActiveDirectory and add the following loginParameters settings: \\\"loginParameters\\\":[ \\\"response_type=code id_token\\\",\\\"scope=openid offline_access profile https://graph.microsoft.com/User.Read\\\" ]\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"[doc2]\": {\n",
    "        \"title\": \"title: Tutorial - Web app accesses Microsoft Graph as the user | Azure\",\n",
    "        \"content\": \"json\\n\\\"identityProviders\\\": { \\\"azureActiveDirectory\\\": { \\\"enabled\\\": true, \\\"login\\\": { \\\"loginParameters\\\":[ \\\"response_type=code id_token\\\", \\\"scope=openid offline_access profile https://graph.microsoft.com/User.Read\\\" ] } } }\\n},\\nSave your settings by selecting PUT. This setting can take several minutes to take effect. Your web app is now configured to access Microsoft Graph with a proper access token. If you don't, Microsoft Graph returns an error saying that the format of the compact token is incorrect.\\nAzure CLI\\nUse the Azure CLI to call the App Service Web App REST APIs to get and update the auth configuration settings so your web app can call Microsoft Graph. Open a command window and login to Azure CLI:\\nazurecli\\naz login\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"[doc3]\": {\n",
    "        \"title\": \"services: microsoft-graph, app-service-web\",\n",
    "        \"content\": \"New-MgServicePrincipalAppRoleAssignment -ServicePrincipalId $managedIdentityObjectId -PrincipalId $managedIdentityObjectId -ResourceId $serverServicePrincipalObjectId -AppRoleId $appRoleId\\n```\\nAzure CLI\\n```azurecli-interactive\\naz login\\nwebAppName=\\\"SecureWebApp-20201106120003\\\"\\nspId=$(az resource list -n $webAppName --query [*].identity.principalId --out tsv)\\ngraphResourceId=$(az ad sp list --display-name \\\"Microsoft Graph\\\" --query [0].id --out tsv)\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"[doc4]\": {\n",
    "        \"title\": \"title: \\\"Quickstart: Configure an app to access a web API\\\"\",\n",
    "        \"content\": \"title: title: \\\"Quickstart: Configure an app to access a web API\\\"\\ndescription: In this quickstart, you configure an app registration representing a web API in the Microsoft identity platform to enable scoped resource access (permissions) to client applications.\\nservices: active-directory\\nauthor: cilwerner\\nmanager: CelesteDG\\nms.service: active-directory\\nms.subservice: develop\\nms.topic: quickstart\\nms.workload: identity\\nms.date: 05/05/2022\\nms.author: cwerner\\nms.custom: aaddev, contperf-fy21q1, mode-api\\nms.reviewer: lenalepa, aragra, sureshja\\ndocument_link: https://github.com/MicrosoftDocs/azure-docs/blob/main/articles/active-directory/develop/quickstart-configure-app-access-web-apis.md\\nIn addition to accessing your own web API on behalf of the signed-in user, your application might also need to access or modify the user's (or other) data stored in Microsoft Graph. Or you might have service or daemon app that needs to access Microsoft Graph as itself, performing operations without any user interaction.\\nDelegated permission to Microsoft Graph\\nConfigure delegated permission to Microsoft Graph to enable your client application to perform operations on behalf of the logged-in user, for example reading their email or modifying their profile. By default, users of your client app are asked when they sign in to consent to the delegated permissions you've configured for it.\\nSign in to the Azure portal.\\nIf you have access to multiple tenants, use the Directories + subscriptions filter :::image type=\\\"icon\\\" source=\\\"./media/quickstart-configure-app-access-web-apis/portal-01-directory-subscription-filter.png\\\" border=\\\"false\\\"::: in the top menu to select the tenant containing your client app's registration.\\nSelect Azure Active Directory > App registrations, and then select your client application.\\nSelect API permissions > Add a permission > Microsoft Graph\\nSelect Delegated permissions. Microsoft Graph exposes many permissions, with the most commonly used shown at the top of the list.\\nUnder Select permissions, select the following permissions:\\n| Permission | Description |\\n|--|--|\\n| email | View users' email address |\\n| offline_access | Maintain access to data you have given it access to |\\n| openid | Sign users in |\\n| profile | View users' basic profile |\\n1. Select Add permissions to complete the process.\\nWhenever you configure permissions, users of your app are asked at sign-in for their consent to allow your app to access the resource API on their behalf.\\nAs an admin, you can also grant consent on behalf of all users so they're not prompted to do so. Admin consent is discussed later in the More on API permissions and admin consent section of this article.\\nApplication permission to Microsoft Graph\\nConfigure application permissions for an application that needs to authenticate as itself without user interaction or consent. Application permissions are typically used by background services or daemon apps that access an API in a \\\"headless\\\" manner, and by web APIs that access another (downstream) API.\\nIn the following steps, you grant permission to Microsoft Graph's Files.Read.All permission as an example.\\nSign in to the Azure portal.\\nIf you have access to multiple tenants, use the Directories + subscriptions filter :::image type=\\\"icon\\\" source=\\\"./media/quickstart-configure-app-access-web-apis/portal-01-directory-subscription-filter.png\\\" border=\\\"false\\\"::: in the top menu to select the tenant containing your client app's registration.\\nSelect Azure Active Directory > App registrations, and then select your client application.\\nSelect API permissions > Add a permission > Microsoft Graph > Application permissions.\\nAll permissions exposed by Microsoft Graph are shown under Select permissions.\\nSelect the permission or permissions you want to grant your application. As an example, you might have a daemon app that scans files in your organization, alerting on a specific file type or name.\\nUnder Select permissions, expand Files, and then select the Files.Read.All permission.\\n1. Select Add permissions.\\nSome permissions, like Microsoft Graph's Files.Read.All permission, require admin consent. You grant admin consent by selecting the Grant admin consent button, discussed later in the Admin consent button section.\\nConfigure client credentials\\nApps that use application permissions authenticate as themselves by using their own credentials, without requiring any user interaction. Before your application (or API) can access Microsoft Graph, your own web API, or another API by using application permissions, you must configure that client app's credentials\"\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"[doc5]\": {\n",
    "        \"title\": \"title: Tutorial - .NET Web app accesses Microsoft Graph as the user | Azure\",\n",
    "        \"content\": \"title: title: Tutorial - .NET Web app accesses Microsoft Graph as the user | Azure\\ndescription: In this tutorial, you learn how to access data in Microsoft Graph for a signed-in user from a .NET web app.\\nservices: microsoft-graph, app-service-web\\nauthor: rwike77\\nmanager: CelesteDG\\ndocument_link: https://github.com/MicrosoftDocs/azure-docs/blob/main/articles/app-service/scenario-secure-app-access-microsoft-graph-as-user.md\\n\\nAzureAd specifies the configuration for the Microsoft.Identity.Web library. In the Azure portal, select Azure Active Directory from the portal menu and then select App registrations. Select the app registration created when you enabled the App Service authentication/authorization module. (The app registration should have the same name as your web app.) You can find the tenant ID and client ID in the app registration overview page. The domain name can be found in the Azure AD overview page for your tenant.\\nGraph specifies the Microsoft Graph endpoint and the initial scopes needed by the app.\\n```json\\n{ \\\"AzureAd\\\": { \\\"Instance\\\": \\\"https://login.microsoftonline.com/\\\", \\\"Domain\\\": \\\"fourthcoffeetest.onmicrosoft.com\\\", \\\"TenantId\\\": \\\"[tenant-id]\\\", \\\"ClientId\\\": \\\"[client-id]\\\", // To call an API \\\"ClientSecret\\\": \\\"[secret-from-portal]\\\", // Not required by this scenario \\\"CallbackPath\\\": \\\"/signin-oidc\\\" },\\n\\\"Graph\\\": { \\\"BaseUrl\\\": \\\"https://graph.microsoft.com/v1.0\\\", \\\"Scopes\\\": \\\"user.read\\\" }, \\\"Logging\\\": { \\\"LogLevel\\\": { \\\"Default\\\": \\\"Information\\\", \\\"Microsoft\\\": \\\"Warning\\\", \\\"Microsoft.Hosting.Lifetime\\\": \\\"Information\\\" } }, \\\"AllowedHosts\\\": \\\"*\\\"\\n}\\n```\\nCall Microsoft Graph on behalf of the user\\nThe following example shows how to call Microsoft Graph as the signed-in user and get some user information. The GraphServiceClient object is injected into the controller, and authentication has been configured for you by the Microsoft.Identity.Web library.\\n```csharp\\n// Index.cshtml.cs\\nusing System.Threading.Tasks;\\nusing Microsoft.AspNetCore.Mvc.RazorPages;\\nusing Microsoft.Graph;\\nusing System.IO;\\nusing Microsoft.Identity.Web;\\nusing Microsoft.Extensions.Logging;\\n// Some code omitted for brevity.\\n[AuthorizeForScopes(Scopes = new[] { \\\"user.read\\\" })]\\npublic class IndexModel : PageModel\\n{ private readonly ILogger _logger; private readonly GraphServiceClient _graphServiceClient;\\n\"\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "```\n",
    "\"\"\"\n",
    "prompt_messages = [\n",
    "    {\"role\": \"system\", \"content\": system_message},\n",
    "    {\"role\": \"user\", \"content\": user_shot_1},\n",
    "    {\"role\": \"assistant\", \"content\": assistant_shot_1},\n",
    "    {\"role\": \"user\", \"content\": user_shot_2},\n",
    "    {\"role\": \"assistant\", \"content\": assistant_shot_2},\n",
    "    {\"role\": \"user\", \"content\": user_question},\n",
    "]\n",
    "\n",
    "completion_response = perform_chat_completion(prompt_messages, type)\n",
    "#print_messages(prompt_messages)\n",
    "print_messages([completion_response[\"choices\"][0][\"message\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "- Example X: Auto Validation\n",
    "- Example X: Query based summarisation\n",
    "- Example X: Edge cases and Responsible AI\n",
    "- Example X: Prime the output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example X: Retrieval Augmented Generation\n",
    "\n",
    "If your use case relies on up-to-date, reliable information and is not purely a creative scenarios then one the most effective ways to provide reliable answers is to give the model data to draw its responses from grounding data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
